\documentclass[12pt]{article}
\usepackage{graphicx,psfrag,amsfonts,float,mathbbol,xcolor,cleveref}
\usepackage{arydshln}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage[mathscr]{euscript}
\usepackage{enumitem}
\usepackage{accents}
\usepackage{framed}
\usepackage{subcaption}
\usepackage{natbib}
\usepackage{mathtools}
\usepackage{IEEEtrantools}
\usepackage{times}
\usepackage{cite}
\usepackage{rotating}
\usepackage{arydshln}
\usepackage{amsthm}
\usepackage[letterpaper, left=1in, top=1in, right=1in, bottom=1in,nohead,includefoot, verbose, ignoremp]{geometry}
\usepackage{booktabs}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\newcommand{\comment}[1]{\text{\phantom{(#1)}} \tag{#1}}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand*\needsparaphrased{\color{red}}
\newcommand*\needscited{\color{orange}}
\newcommand*\needsproof{\color{blue}}
\newcommand*\outlineskeleton{\color{green}}
\newcommand{\PP}{\mathcal{P}}
\newcommand{\bfeps}{\mbox{\boldmath $\epsilon$}}
\newcommand{\bfgamma}{\mbox{\boldmath $\gamma$}}
\newcommand{\bflam}{\mbox{\boldmath $\lambda$}}
\newcommand{\bfphi}{\mbox{\boldmath $\phi$}}
\newcommand{\bfsigma}{\mbox{\boldmath $\sigma$}}
\newcommand{\bfbeta}{\mbox{\boldmath $\beta$}}
\newcommand{\bfalpha}{\mbox{\boldmath $\alpha$}}
\newcommand{\bfe}{\mbox{\boldmath $e$}}
\newcommand{\bff}{\mbox{\boldmath $f$}}
\newcommand{\bfone}{\mbox{\boldmath $1$}}
\newcommand{\bft}{\mbox{\boldmath $t$}}
\newcommand{\bfo}{\mbox{\boldmath $0$}}
\newcommand{\bfO}{\mbox{\boldmath $O$}}
\newcommand{\bfx}{\mbox{\boldmath $x$}}
\newcommand{\bfX}{\mbox{\boldmath $X$}}
\newcommand{\bfz}{\mbox{\boldmath $z$}}


\newcommand{\bfm}{\mbox{\boldmath $m}}
\newcommand{\bfy}{\mbox{\boldmath $y$}}
\newcommand{\bfa}{\mbox{\boldmath $a$}}
\newcommand{\bfb}{\mbox{\boldmath $b$}}
\newcommand{\bfY}{\mbox{\boldmath $Y$}}
\newcommand{\bfS}{\mbox{\boldmath $S$}}
\newcommand{\bfZ}{\mbox{\boldmath $Z$}}
\newcommand{\cardT}{\vert \mathcal{T} \vert}
%\newenvironment{theorem}[1][Theorem]{\begin{trivlist}
%\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
%\newenvironment{corollary}[1][Corollary]{\begin{trivlist}
%\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
%\newenvironment{proposition}[1][Proposition]{\begin{trivlist}
%\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
%\newenvironment{definition}[1][Definition]{\begin{trivlist}
%\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\def\bL{\mathbf{L}}

\begingroup\lccode`~=`_
\lowercase{\endgroup\def~}#1{_{\scriptscriptstyle#1}}
\AtBeginDocument{\mathcode`_="8000 \catcode`_=12 }

\makeatletter
\renewcommand{\theenumi}{\Roman{enumi}}
\renewcommand{\labelenumi}{\theenumi.}
\renewcommand{\theenumii}{\Alph{enumii}}
\renewcommand{\labelenumii}{\theenumii.}
\renewcommand{\p@enumii}{\theenumi.}
\makeatother

\begin{document}

%\nocite{*}
\def\bL{\mathbf{L}}
%\usepackage{mathtime}

%%UNCOMMENT following line if you have package


\title{ Nonparametric Covariance Estimation for Longitudinal Data via Penalized Tensor Product Splines}

\author{Tayler A. Blake\thanks{The Ohio State University, 1958 Neil Avenue, Columbus, OH 43201} \and  Yoonkyung Lee\thanks{The Ohio State University, 1958 Neil Avenue, Columbus, OH 43201}}

\bibliographystyle{plainnat}
\maketitle

\section{Performance}
In this section, we evaluate the performance of the spline estimator under different simulation settings when the tuning parameters are chosen by the unbiased risk estimate and leave-one-subject-out cross validation. We compare the performance of the maximum penalised likelihood estimator using the classical smoothness penalty under the smoothing spline representation to the performance of the tensor product P-spline estimator for varying orders of the penalty. We also compare performance under complete data to the performance under irregularly sampled data:

\begin{itemize}
\item All subjects share a common set of observation times $t_1, \dots, t_M$.
\item Observation times vary across subjects, with subject-specific deviation defined as follows: 
\end{itemize}

For the case of common observation times across all subjects, we also consider three other methods of estimating a covariance matrix for comparison: the sample covariance matrix $\Sigma^*$, the soft thresholding estimator of \citet{rothman2009generalized}, and the tapering estimator of \citet{cai2010optimal}. The soft-thresholding estimator proposed in \citet{rothman2009generalized} is given by

\[
\hat{\Sigma}^{sthresh}\left(\lambda\right) =   \begin{bmatrix} \mbox{sign}\left(\sigma^*_{ij}\right) \left(\sigma^*_{ij} - \lambda\right)_+ \end{bmatrix},
\]
\noindent 
where $\sigma^*_{ij}$ denotes the $i$-$j^{th}$ entry of the sample covariance matrix, and $\lambda$ is a penalty parameter controlling the amount of shrinkage applied to the empirical estimator. The tapering estimator presented in \citet{cai2010optimal} is defined
\[
\hat{\Sigma}^{taper}\left(\lambda\right) =  \begin{bmatrix} \omega_{ij}^\lambda \sigma^*_{ij} \end{bmatrix}.
\]
\noindent
The weights $\omega_{ij}^\lambda$ are given by 
\begin{equation*}
\omega_{ij} = k_h^{-1} \left[ \left( k - \vert i-j\vert\right)_+ - \left(k_h - \vert i-j\vert\right)_+ \right],
\end{equation*}
\noindent
where $k_h = k/2$ is assumed to be even without loss of generality. These may be rewritten as
\begin{align*}
\omega_{ij} = \left\{\begin{array}{ll} 1, & \vert \vert i -j \vert \vert \le k_h \\
                             2 - \frac{i - j}{k_h} & k_h < \vert \vert i -j \vert \vert \le k, \\
                             0 & \mbox{otherwise}  \end{array} \right.
\end{align*}
\noindent
The subscript on the weights $\omega_{ij}$ serves to indicate that these are controlled by a tuning parameter which controls the amount of shrinkage applied to the elements of the sample covariance matrix.

[discuss the MCRE and CVTuningCov package]

\bigskip

[discuss the implementation and R package here]

To assess performance of estimator $G$, we consider two commonly used loss functions:
\begin{equation}
\Delta_1\left(\Sigma,G \right) = tr\left( \Sigma^{-1} G \right) - log \vert \Sigma^{-1} G \vert - M,
\end{equation}
\noindent
\begin{equation}
\Delta_2\left(\Sigma,G\right) = tr\left(\left( \Sigma^{-1} G - \mathrm{I}\right)^2 \right)
\end{equation}
\noindent
where $\Sigma$ is the true covariance matrix and $G$ is an $M \times M$ positive definite matrix. Each of these loss functions are $0$ when $G = \Sigma$ and is positive when $G != \Sigma$. Both are invariant with respect to transformations
\[
G^* = C G C', \quad \Sigma^* = C \Sigma C',
\]
\noindent
for a nonsingular matrix $C$. The first loss $\Delta_1$ is commonly referred to as the entropy loss; it gives the Kullback-Leibler divergence of two multivariate Normal densities corresponding to the two covariance matrices. The second loss $\Delta_2$, or the quadratic loss, measures the Euclidean or Frobenius norm of its matrix argument, and consequently penalizes overestimates more than underestimates, so ``smaller'' estimates are favored more under $\Delta_2$ than $\Delta_1$. We obtain the corresponding risk functions by taking expectations,

\begin{equation*}
R_i \left(\Sigma, G\right) = E_\Sigma\left[\Delta_i\left(\Sigma,G\right)\right], \quad i = 1,2.
\end{equation*}
\noindent
We prefer estimator $\hat{\Sigma}_1$ over another estimator $\hat{\Sigma}_2$ if $R_i \left(\Sigma, \hat{\Sigma}_2\right) < R_i \left(\Sigma, \hat{\Sigma}_2\right)$. We estimate the risk functions by Monte Carlo approximation, using $N_{sim} = 100$ simulation runs for each scenario outlined above.  Estimation is performed on data generated according to an $M$-dimensional multivariate Normal distribution with mean zero; we consider four Cholesky covariance structures for the underlying generating distribution:

\begin{enumerate} 
\item Mutual independence: $\Sigma_1 = T^{-T} D^2 T^{-1} = \mathrm{I}$ where 
\begin{align*}
\phi\left(t,s\right) &= 0, \quad 1 \le t < s \le M;\\ 
\sigma^2\left(t\right) &= 1, \quad t = 1,\dots, M.
\end{align*}
\item Linear varying coefficient model with constant innovation variance: $\Sigma_2 = T^{-T} D^2 T^{-1}$ where 
\begin{align*}
\phi\left(t,s\right) &= t - \frac{1}{2M}, \quad 1 \le s < t \le M \\
\sigma^2\left(t\right) &= 0.1, \quad t = 1,\dots, M.
\end{align*}
\item $\mbox{AR}\left(k\right)$ model with linear varying coefficient: $\Sigma_3 = T^{-T} D^2 T^{-1}$ where $k = \lfloor M/2\rfloor + 1$ and 
\begin{align*}
\phi\left(t,s\right) &= \left\{\begin{array}{ll} t - \frac{1}{2M}, & t - s \le \lfloor M/2\rfloor + 1\\ 
0, & t - s > 1\end{array}\right.,\\
\sigma^2\left(t\right) &= 0.1, \quad t = 1,\dots, M.
\end{align*}
\item $\mbox{AR}\left(1\right)$ model with linear varying coefficient: $\Sigma_3 = T^{-T} D^2 T^{-1}$ where 
\begin{align*}
\phi\left(t,s\right) &= \left\{\begin{array}{ll} t - \frac{1}{2M}, & t - s = 1\\ 0, & t - s > 1\end{array}\right.,\\
\sigma^2\left(t\right) &= 0.1, \quad t = 1,\dots, M.
\end{align*}
\item The compound symmetry model: $\Sigma_4 = \sigma^2\left(\rho \mathrm{J} + \left(1-\rho\right)\mathrm{I}\right),\; \rho=0.7,\;\sigma^2=1$. 
\begin{align*}
\phi_{ts} &= -\frac{\rho}{1 + \left(t-1\right)\rho}, \quad t = 2, \dots, M,\;\; s = 1, \dots, t-1\\
\sigma_t^2 &= 1 -\frac{\left(t-1\right)\rho^2}{1 + \left(t-1\right)\rho}, \;\; t = 2, \dots, M.
\end{align*}
\end{enumerate}


\setlength{\dashlinedash}{0.5pt}
\setlength{\dashlinegap}{1pt}
\setlength{\arrayrulewidth}{0.2pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}[ht]
\caption{Simulation results for $\Sigma_1 = \mathrm{I}$ under quadratic loss, $\Delta_1$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
\centering
\begin{tabular}{lrrrrr}
& M & \multicolumn{2}{c}{$\hat{\Sigma}_{ssanova}$} & $S$ \\ 
& & \mbox{LosoCV} & \mbox{URE} &  \\   \hline
		&    10 & 0.0010 && 0.4702 \\ 
$N = 50$  &    20 & 0.0007 && 0.8495 \\ 
  		&    30 & 0.0003 && 1.1449 \\ \hdashline
		 &    10 & 0.0004 && 0.2072 \\ 
$N = 100$ &    20 & 0.0002 && 0.3920 \\ 
   &    30 & 0.0001 & &0.5712 \\ 
   \hline
\end{tabular}
\end{table}


%% entropy risk
\begin{table}[ht]
\centering
\begin{tabular}{lrrrrr}
& M & \multicolumn{2}{c}{$\hat{\Sigma}_{ssanova}$} & $S$ \\ 
& & \mbox{LosoCV} & \mbox{URE} &  \\   \hline
&    10 & 0.0684 & &1.2339 \\ 
$N = 50$ &    20 & 0.0799 & &5.0827 \\ 
  &    30 & 0.0668 & &12.5162 \\ 
   \hdashline
 &    10 & 0.0405 && 0.5854 \\ 
$N = 100$ &    20 & 0.0356 && 2.3038 \\ 
  &    30 & 0.0396 & &5.2641 \\ 
\end{tabular}
\end{table}

%-------------------------------------------------------------------------------------------------------------------------------------------

\begin{table}[ht]
\centering
\caption{Simulation results for $\Sigma_2$, the  linear varying coefficient AR model, under quadratic loss, $\Delta_1$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
\begin{tabular}{lrrrrr}
& M & \multicolumn{2}{c}{$\hat{\Sigma}_{ssanova}$} & $S$ \\ 
& & \mbox{LosoCV} & \mbox{URE} &  \\   \hline
&    10 & 0.0314 & &0.5726 \\ 
$N = 50 $ &    20 & 0.3266 && 2.3130 \\ 
 &    30 & 5.0696 & &15.1096 \\ \hdashline
 &    10 & 0.0156 && 0.2479 \\ 
$N = 100$ &    20 & 0.1894 & &1.3177 \\ 
  &    30 & 2.3876 && 8.3983 \\ 
   \hline
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\caption{Simulation results for $\Sigma_2$, the linear varying coefficient AR model, under entropy loss, $\Delta_2$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
\begin{tabular}{lrrrrr}
& M & \multicolumn{2}{c}{$\hat{\Sigma}_{ssanova}$} & $S$ \\ 
& & \mbox{LosoCV} & \mbox{URE} &  \\   \hline
  \hline
 &    10 & 0.0647 & & 1.2431 \\ 
$N = 50$ &    20 & 0.0884 & & 5.0437 \\ 
&    30 & 0.0702 & & 12.4559 \\ 
   \hdashline
&    10 & 0.0307 & & 0.5403 \\ 
$N = 100 $ &    20 & 0.0357 & & 2.3195 \\ 
   &    30 & 0.0372 & & 5.2817 \\ 
\end{tabular}
\end{table}

%-------------------------------------------------------------------------------------------------------------------------------------------

\begin{table}[ht]
\centering
\caption{Simulation results for $\Sigma_3$, the k-banded linear varying coefficient AR model with $k = \lfloor M/2\rfloor + 1$, under quadratic loss, $\Delta_1$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}

\begin{tabular}{lrrrrr}
& M & \multicolumn{2}{c}{$\hat{\Sigma}_{ssanova}$} & $S$ \\ 
& & \mbox{LosoCV} & \mbox{URE} &  \\   \hline  \hline
 	          &    10 & 0.0562 & & 0.5237 \\ 
 $N = 50$ 	 &     20 & 0.7832 & & 2.1419 \\ 
  		  &    30 & 8.2650 & & 15.2842 \\ \hdashline
		  &    10 & 0.0376 & &0.2546 \\ 
 $N = 100$  &    20 & 0.6260 & & 1.3751 \\ 
   &    30 & 5.7635 && 7.4750 \\ 
   \hline
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\caption{Simulation results for $\Sigma_3$, the k-banded linear varying coefficient AR model with $k = \lfloor M/2\rfloor + 1$, under entropy loss, $\Delta_2$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
\begin{tabular}{lrrrrr}
& M & \multicolumn{2}{c}{$\hat{\Sigma}_{ssanova}$} & $S$ \\ 
& & \mbox{LosoCV} & \mbox{URE} & \\   \hline
  \hline
&    10 & 0.3354 &&  1.1947 \\ 
$N = 50$ &    20 & 1.1144 &&  5.0966 \\ 
  &    30 & 2.3247 & &  12.4905 \\ 
   \hdashline
    &    10 & 0.2826 & & 0.5446 \\ 
  $N = 100$ &    20 & 1.0690 & & 2.3514 \\ 
   &    30 & 2.2737 & & 5.4204 \\ 
\end{tabular}
\end{table}

%-------------------------------------------------------------------------------------------------------------------------------------------

\begin{table}[ht]
\centering
\caption{Simulation results for $\Sigma_4$, the 2-banded linear varying coefficient AR model, under quadratic loss, $\Delta_1$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
\begin{tabular}{lrrrrr}
& M & \multicolumn{2}{c}{$\hat{\Sigma}_{ssanova}$} & $S$ \\ 
& & \mbox{LosoCV} & \mbox{URE} &  \\   \hline
 &    10 & 0.0134 & & 0.4169 \\ 
$N = 50$ &    20 & 0.0590 & & 0.8810 \\ 
 &    30 & 0.1351 & & 1.2571 \\ \hdashline
     &    10 & 0.0077 & & 0.2263 \\ 
  $N = 100$ &    20 & 0.0549 & & 0.4309 \\ 
   &    30 & 0.1331 & & 0.6819 \\
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\caption{Simulation results for $\Sigma_4$, the 2-banded linear varying coefficient AR model, under entropy loss, $\Delta_2$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}

\begin{tabular}{lrrrrr}
& M & \multicolumn{2}{c}{$\hat{\Sigma}_{ssanova}$} & $S$ \\ 
& & \mbox{LosoCV} & \mbox{URE} & $S$ \\ 
  \hline
&    10 & 0.2605 & &  1.1692 \\ 
$N = 50$ &    20 & 0.8836 &  & 5.0899 \\ 
   &    30 & 1.6087 & &12.5844 \\ \hdashline
 &    10 & 0.2193 && 0.5642 \\ 
  $N = 100$ &    20 & 0.8468 && 2.2607 \\ 
   &    30 & 1.5743 && 5.2437 \\
  \end{tabular}
\end{table}

%-------------------------------------------------------------------------------------------------------------------------------------------

\begin{table}[ht]
\centering
\caption{Simulation results for $\Sigma_5$, the compound symmetry model, under quadratic loss, $\Delta_1$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}

\begin{tabular}{lrrrrr}
& M & \multicolumn{2}{c}{$\hat{\Sigma}_{ssanova}$} & $S$ \\ 
& & \mbox{LosoCV} & \mbox{URE} & $S$ \\ 
  \hline
 &    10 & 0.3688 & & 0.7872 \\ 
$N = 50$ &    20 & 0.9770 & & 1.6167 \\ 
  &    30 & 1.6067 &&  2.5548 \\ \hdashline
  &    10 & 0.3210 & & 0.3913 \\ 
  $N = 100$ &    20 & 0.9793 &  &  0.8385 \\ 
   &    30 & 1.6177 & & 1.2383 \\ 
   \hline
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\caption{Simulation results for $\Sigma_5$, the compound symmetry model, under entropy loss, $\Delta_2$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
\begin{tabular}{lrrrrr}
& M & \multicolumn{2}{c}{$\hat{\Sigma}_{ssanova}$} & $S$ \\ 
&  & \mbox{LosoCV} & \mbox{URE} & $S$ \\ 
  \hline
 &    10 & 0.2837 & & 1.1943 \\ 
$N = 50$&    20 & 0.7551& & 5.0283 \\ 
  &    30 & 1.1936 & & 12.5871 \\ \hdashline
 &    10 & 0.2449 & & 0.5734 \\ 
  $N = 100$ &    20 & 0.7231 & & 2.2678 \\ 
   &    30 & 1.1780 & &5.2562 \\
  \end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{table}\centering
%\ra{1.3}
%\caption{Simulation results for $\Sigma_2$, the linear varying coefficient AR model, under quadratic loss, $\Delta_1$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
%\begin{tabular}{@{}rrrcrcrrcrr@{}}\toprule
%   &            & \multicolumn{1}{c}{$\Sigma^*$}  & \multicolumn{1}{c}{$\hat{\Sigma}^{taper}$} &\multicolumn{1}{c}{$\hat{\Sigma}^{ST}$} &\multicolumn{2}{c}{ $\hat{\Sigma}^{ssanova}$} &  \multicolumn{2}{c}{ $\hat{\Sigma}^{tps}$}\\
%$N$ & $M$ 	&	  &	& & \multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}} &\multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}}\\ \midrule
%$50$ & $10$ &	0.0562 0.5237	&&&& 	0.0562	&&\\
%  & $20$  &    2.1419&&&&   0.7832		&&\\
%  & $30$   &    15.2842 &&&&  18.2650    &&\\ \midrule
%$100$ & $10$ &&&&&&&\\
%& $20$  &&&&&&& \\
%& $30$  &&&&&	&& \\
%\bottomrule
%\end{tabular}
%\end{table}
%

%\begin{table}\centering
%\ra{1.3}
%\caption{Simulation results for $\Sigma_2$, the linear varying coefficient AR model, under entropy loss, $\Delta_2$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
%\begin{tabular}{@{}rrrcrcrrcrr@{}}\toprule
%   &            & \multicolumn{1}{c}{$\Sigma^*$}  & \multicolumn{1}{c}{$\hat{\Sigma}^{taper}$} &\multicolumn{1}{c}{$\hat{\Sigma}^{ST}$} &\multicolumn{2}{c}{ $\hat{\Sigma}^{ssanova}$} &  \multicolumn{2}{c}{ $\hat{\Sigma}^{tps}$}\\
%$N$ & $M$ 	&	  &	& & \multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}} &\multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}}\\ \midrule
%$50$ & $10$  & 1.1861	&&&&	0.0800&&\\
%  & $20$  &   5.1155 &&&&    0.0730	&&\\
%  & $30$   &  12.5243   &&&&  0.0789	&&\\ \midrule
%$100$ & $10$ &&&&&	&&\\
%& $20$  &&&&&&& \\
%& $30$  &&&&&&& \\
%\bottomrule
%\end{tabular}
%\end{table}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\begin{table}[ht]
%\centering
%\begin{tabular}{rrrrr}
%  \hline
% & N & M & my\_quad\_risk & s\_quad\_risk \\ 
%  \hline
%1 & 50.000 &   10 & 0.031 & 0.573 \\ 
%  2 & 50.000 &   20 & 0.327 & 2.313 \\ 
%  3 & 50.000 &   30 & 5.070 & 15.110 \\ 
%   \hline
%\end{tabular}
%\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
%\begin{table}\centering
%\ra{1.3}
%\caption{Simulation results for $\Sigma_3$, the linear $\mbox{AR}\left(1\right)$ model under quadratic loss, $\Delta_1$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
%\begin{tabular}{@{}rrrcrcrrcrr@{}}\toprule
%   &            & \multicolumn{1}{c}{$\Sigma^*$}  & \multicolumn{1}{c}{$\hat{\Sigma}^{taper}$} &\multicolumn{1}{c}{$\hat{\Sigma}^{ST}$} &\multicolumn{2}{c}{ $\hat{\Sigma}^{ssanova}$} &  \multicolumn{2}{c}{ $\hat{\Sigma}^{tps}$}\\
%$N$ & $M$ 	&	  &	& & \multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}} &\multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}}\\ \midrule
%$50$ & $10$&0.4086 &&&&	   0.0145	&&\\\\
%  & $20$  &0.9926 &&&&	0.0609  &&\\
%  & $30$   & 1.2884 &&&&	0.1387 &&\\
%$100$ & $10$ &&&&&&&\\
%& $20$  &&&&&&& \\
%& $30$  &&&&&&& \\
%\bottomrule
%\end{tabular}
%\end{table}

%
%\begin{table}\centering
%\ra{1.3}
%\caption{Simulation results for $\Sigma_3$, the linear $\mbox{AR}\left(1\right)$ model, under entropy loss, $\Delta_2$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
%\begin{tabular}{@{}rrrcrcrrcrr@{}}\toprule
%   &            & \multicolumn{1}{c}{$\Sigma^*$}  & \multicolumn{1}{c}{$\hat{\Sigma}^{taper}$} &\multicolumn{1}{c}{$\hat{\Sigma}^{ST}$} &\multicolumn{2}{c}{ $\hat{\Sigma}^{ssanova}$} &  \multicolumn{2}{c}{ $\hat{\Sigma}^{tps}$}\\
%$N$ & $M$ 	&	  &	& & \multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}} &\multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}}\\ \midrule
%$50$ & $10$& 1.2023 &&&& 0.2750 &&\\
%  & $20$  & 5.0599  &&&& 0.8759 &&\\
%  & $30$   &  12.3077  &&&&1.6266 &&\\
%$100$ & $10$ &&&&&&&\\
%& $20$  &&&&&&& \\
%& $30$  &&&&&&& \\
%\bottomrule
%\end{tabular}
%\end{table}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{table}\centering
%\ra{1.3}
%\caption{Simulation results for $\Sigma_4$, the compound symmetry model, under quadratic loss, $\Delta_1$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
%\begin{tabular}{@{}rrrcrcrrcrr@{}}\toprule
%   &            & \multicolumn{1}{c}{$\Sigma^*$}  & \multicolumn{1}{c}{$\hat{\Sigma}^{taper}$} &\multicolumn{1}{c}{$\hat{\Sigma}^{ST}$} &\multicolumn{2}{c}{ $\hat{\Sigma}^{ssanova}$} &  \multicolumn{2}{c}{ $\hat{\Sigma}^{tps}$}\\
%$N$ & $M$ 	&	  &	& & \multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}} &\multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}}\\ \midrule
%$50$ & $10$ & 47.4073  &&&& 4.8320 && \\
%  & $20$  &  104.8177  &&&& 5.5327 &&\\
%  & $30$   &  151.9395  &&&& 5.6466 &&\\  \midrule
%$100$ & $10$ &&&&&&&\\
%& $20$  &&&&&&& \\
%& $30$  &&&&&&& \\
%\bottomrule
%\end{tabular}
%\end{table}

%\begin{table}\centering
%\ra{1.3}
%\caption{Simulation results for $\Sigma_4$, the compound symmetry model,  under entropy loss, $\Delta_2$. The risk functions for the sample covariance matrix, the tapered estimator, the soft thresholding estimator, the SSANOVA Cholesky estimator, and the tensor product P-spline Cholesky estimator were estimated using Monte Carlo simulation, with $N_sim = 100$ simulation trials. The tuning parameters for the tapering estimator and the soft thresholding estimator were chosen using $K = 5$-fold cross validation. The performance of the spline estimators is evaluated when both the unbiased risk estimate and leave-one-subject-out cross validation are used to select the smoothing parameters.}
%\begin{tabular}{@{}rrrcrcrrcrr@{}}\toprule
%   &            & \multicolumn{1}{c}{$\Sigma^*$}  & \multicolumn{1}{c}{$\hat{\Sigma}^{taper}$} &\multicolumn{1}{c}{$\hat{\Sigma}^{ST}$} &\multicolumn{2}{c}{ $\hat{\Sigma}^{ssanova}$} &  \multicolumn{2}{c}{ $\hat{\Sigma}^{tps}$}\\
%$N$ & $M$ 	&	  &	& & \multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}} &\multicolumn{1}{c}{\mbox{URE}} & \multicolumn{1}{c}{\mbox{losoCV}}\\ \midrule
%$50$ & $10$ &	14.6842  &&&&	3.9489	&&\\
%  & $20$  &    36.5299	&&&&  4.6406	&&\\
%  & $30$   &    59.5043	&&&&  4.9214	&&\\
%$100$ & $10$ &&&&&&&\\
%& $20$  &&&&&&& \\
%& $30$  &&&&&&& \\
%\bottomrule
%\end{tabular}
%\end{table}

\section{Discussion}

See \citet{pourahmadi2011covariance} section 3.1 for further discussion of loss functions

\end{document}
