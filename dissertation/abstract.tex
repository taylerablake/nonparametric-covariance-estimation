%  The dissertation abstract can only be 500 words.


\begin{quote}
%
%With high dimensional longitudinal and functional data becoming much more common, there is a strong need for methods of estimating large covariance matrices. Estimation is made difficult by the instability of sample covariance matrices in high dimensions and a positive- definite constraint we desire to impose on estimates. A Cholesky decomposition of the covariance matrix allows for parameter estimation via unconstrained optimization as well as a statistically meaningful interpretation of the parameter estimates. Regularization improves stability of covariance estimates in high dimensions, as well as in the case where functional data are sparse and individual curves are sampled at different and possibly unequally spaced time points. By viewing the entries of the covariance matrix as the evaluation of a continuous bivariate function at the pairs of observed time points, we treat covariance estimation as bivariate smoothing.
%Within regularization framework, we propose novel covariance penalties which are designed to yield natural null models presented in the literature for stationarity or short-term dependence. These penalties are expressed in terms of variation in continuous time lag and its orthogonal complement. We present numerical results and data analysis to illustrate the utility of the proposed method.
%
%\bigskip
\doublespacing
Estimation of an unstructured covariance matrix is difficult because of the challenges posed by parameter space dimensionality and the positive definiteness constraint that estimates should satisfy. We propose a general framework for nonparametric covariance estimation for longitudinal data where the variables have a natural ordering. Modeling the Cholesky decomposition of the covariance matrix removes constraints from estimation, including those posed by positive definiteness. In addition, the Cholesky decomposition enjoys the added advantage over alternative matrix decompositions by supplying a meaningful statistical interpretation of the corresponding estimated parameters. We illustrate the equivalence of covariance estimation and the estimation of a varying coefficient autoregressive model. By defining the varying coefficient as a bivariate function, we naturally accommodate sparsely or irregularly sampled longitudinal data without the need for imputation. 

\bigskip

This framework extends the set of tools available for covariance estimation to any of those employed in the typical function estimation setting. Viewing stationarity as a form of simplicity or parsimony in covariance models, we specify the varying coefficient as a function so that we can conveniently penalize the components capturing the nonstationarity in the fitted function. Casting covariance estimation as bivariate smoothing problem, we demonstrate construction of a covariance estimator using the smoothing spline framework and a penalized B-spline expansion.
\bigskip
A simulation study establishes the advantage of our estimator over alternative estimators proposed in this setting. We analyze a longitudinal dataset to illustrate application of the methodology and compare our estimates to those resulting from alternative models proposed for the covariance for longitudinal data. 



\end{quote}


