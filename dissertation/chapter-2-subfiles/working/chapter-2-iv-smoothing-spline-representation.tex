

Recall that the joint likelihood of the data $Y_1,\dots, Y_N$ is satisfies

\begin{equation} \label{eq:penalized-joint-loglik-given-phi-2}
-2\ell\left( Y_1,\dots, Y_N, \phi, \kappa \right) =  \sum_{i = 1}^N \sum_{j = 1}^{m_i} \log \sigma^2_{ij}  + \sum_{i = 1}^N \sum_{j = 1}^{m_i} \frac {\epsilon_{ij}^2}{\sigma^2_{ij}};
\end{equation}
\noindent
Let 

\begin{equation}
\mbox{RSS}\left( t \right) = \sum_{i,j:t_{ij}= t} \left( y_{ij} - \sum_{k<j} \phi_{ijk} y_{ik}\right)^2
\end{equation}
\noindent
denote the squared residuals for the observations $y_{ij}$ having corresponding measurement time $t_{ij} - t$. Then $\mbox{RSS}\left( t \right)/\sigma^2\left(t\right) \sim \chi^2_{df_t}$, where the degrees of freedom $df_{t}$ corresponds to the number of observations $y_{ij}$ having corresponding measurement time $t$. In this light, for fixed $\phi$, the penalized likelihood \ref{eq:penalized-joint-loglik-given-phi-2} is that of a variance model with the $\epsilon_{ij}^2$ serving as the response. This corresponds to a generalized linear model with gamma errors and known scale parameter equal to 2.



