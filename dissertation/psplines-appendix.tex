\chapter{Chapter~\ref{psplines-chapter}} \label{psplines-appendix}

\section{Connecting the finite difference penalty to B-spline derivatives}

The evaluation of the $i^{th}$ B-spline using the recursive relation (\ref{eq:bspline-recursive-relation}) can be derived from their definition as divided differences of truncated power functions.  

\begin{definition} \label{definition:order_k_Bspline}
Let $t= \left\{ t_i \right\}$ denote a non-decreasing sequence. The $i^{th}$ B-spline of order $k$ which corresponds to the knot sequence $t$ is defined by 
\begin{equation} \label{eq:bspline_definition}
B_{i,k,t}\left(x\right) = \left(t_{i+k}-t_i\right)\left[t_i,\dots,t_{i+k}\right]\left(\cdot -x\right)_+^{k-1}
\end{equation}
\end{definition}

The placeholder notation, $\left(\cdot - x\right)_+^{k-1}$, is used to indicate that the $k^{th}$ divided difference of the truncated power function $g\left(t \right) = \left(t-x\right)^{k-1}_+$ is obtained by fixing $x$ and applying the divided difference to $g\left(t \right)$ as a function of $t$ alone. Henceforth, we will write $B_{ik}$ rather than $B_{i,k,t}$ when the knot sequence can be inferred from surrounding context.

\bigskip

The definition of $B_i$ as a divided difference is necessary to bridge the expression for its derivative to the differences of its coefficients. The derivative of the truncated power function $g\left(x\right) = \left(t-x\right)_+^{k-1}$ is given by 
\[
\frac{\partial}{\partial x}g\left(x\right) = \frac{\partial}{\partial x} \left(t-x\right)_+^{k-1} = -\left(k-1\right)\left(t-x\right)_+^{k-2}.
\]

\noindent
Substituting \ref{eq:bspline_definition} into the recursive relation (\ref{eq:bspline-recursive-relation}), we may write the derivative of the $i^{th}$ B-spline of order $k$ as follows:
\begin{align*}
 B'_{i,k}\left(x\right) &= \bigg[ \left[ t_{i+1},\dots,t_{i+k} \right] -\left[ t_{i},\dots,t_{i+k-1} \right] \bigg] \frac{\partial}{\partial x} \left(\cdot - x\right)_+^{k-1}\\
&= -\left(k-1\right) \bigg[ \left[ t_{i+1},\dots,t_{i+k} \right] -\left[ t_{i},\dots,t_{i+k-1} \right] \bigg] \left( \cdot - x \right)^{k-2}_+ \\
&= -\left(k-1\right) \bigg[ -\frac{B_{i+1,k-1}\left(x\right)}{\left(t_{i+k} - t_{i+1} \right)}  + \frac{B_{i,k-1}\left(x\right)}{\left(t_{i+k-1} - t_{i} \right)} \bigg]  
\end{align*}

\noindent
This allows us to write 
\begin{align} 
\frac{\partial}{\partial x} \bigg[ \sum_{i} \theta_i B_i \bigg] &=  \sum_i \theta_i B'_{i,k}\nonumber \\
&= \sum_i \left(k-1\right) \frac{\theta_i - \theta_{i-1}}{t_{i+k-1}-t_i}B_{i,k-1}. \label{eq:bspline-derivative}
\end{align}  

Note that the limits on the previous summation in \ref{eq:bspline-derivative} are left unspecified; the formula is written for bi-infinite sums, and their application to finite sums is accessible after they are written formally as bi-infinite sums by augmenting the appropriate zero terms. However, if we are interested in a particular interval over the domain, say $\left[t_r,t_s\right]$, then for $x \in \left[t_r,t_s\right]$, then


\[
\frac{\partial}{\partial x} \bigg[ \sum_i \theta_i B_{i,k}\left(x\right) \bigg]  = \sum_{r-k+2}^{s-1}\left(k-1\right) \frac{\theta_i-\theta_{i-1}}{t_{i+k-1} - t_i}B_{i,k-1}\left(x\right)
\]

\noindent
since $B_{i,k-1}\left(x\right)=0$ for all $i \not \in \left\{r-k+2,\dots, s-1 \right\}$ when $t_r \le x\le t_s$. Applying \ref{eq:bspline-derivative} $j$ times gives us that the $j^{th}$ derivative of $f = \sum_{i} \theta_i B_{ik}$ has form


\begin{align}
\frac{\partial^j}{\partial x^j} \bigg[ \sum_i \theta_i B_{i,k}\left(x\right) \bigg] =  \sum_i \theta_i^{\left(j+1\right)} B_{i,k-j} \label{eq:BS_jth_deriv_a} \\
\theta_i^{\left(j+1\right)} \equiv \left\{ \begin{array}{cl} \theta_i, & j = 0 \\
						\frac{\theta_i^{\left(j\right)} - \theta_{i-1}^{\left(j\right)} }{\left( t_{i+k-j}-t_{i}\right)/\left(k-j\right)}, & j \ge 1 
  \end{array} \right.\label{eq:BS_jth_deriv_b}
\end{align}

\begin{proof}
We proceed by induction on $j$. We have already shown the case for $j=1$ in the derivation of \ref{eq:bspline-derivative}. Assume that the statement holds for some $j^* >1$, so that we have
\[
\frac{\partial^{j^*}}{\partial x^{j^*}} \bigg[ \sum_i \theta_i B_{i,k}\left(x\right) \bigg] = \sum_i \frac{\theta_i^{\left(j^*\right)} - \theta_{i-1}^{\left(j^*\right)} }{\left( t_{i+k-{j^*}}-t_{i}\right)/\left(k-{j^*}\right)} B_{i,k-j^*}\left(x\right).
\]

\noindent
Then the $\left( j^* + 1 \right)^{st}$ derivative is given by 
\begin{align*}
\frac{\partial^{j^*+1}}{\partial x^{j^*+1}} \bigg[ \sum_i \theta_i B_{i,k} \bigg] &= \sum_i \frac{\theta_i^{\left(j^*\right)} - \theta_{i-1}^{\left(j^*\right)} }{\left( t_{i+k-{j^*}}-t_{i}\right)/\left(k-{j^*}\right)}  B'_{i,k-j^*} \\
&= \sum_i \theta_i^{\left(j^*\right)}  B'_{i,k-j^*} \\
&= \sum_i \theta_i^{\left(j^*\right)} \left(k-\left(j^*+1\right)\right)\bigg[ \frac{B_{i,k-\left(j^*+1\right)}}{t_{i+k-\left({j^*}+1\right)}-t_{i}} - \frac{ B_{i+1,k-\left(j^*+1\right)} }{ t_{i+k-\left({j^*}+1\right)+1}-t_{i+1}} \bigg] \\
&= \sum_i \frac{\theta_i^{\left(j^*\right)} - \theta_{i-1}^{\left(j^*\right)}}{\left(t_{i+k-\left(j^* + 1\right)}-t_i\right)/\left(k-\left(j^*+1\right)\right)}B_{i,k-\left(j^* + 1\right)}\\
&= \sum_i \theta_i^{\left(j^*+1\right)}  B_{i,k-\left(j^* + 1\right)}
\end{align*}
\end{proof}
The choice to write $k-j$ as a divisor in the denominator lends to the interpretation of \ref{eq:BS_jth_deriv_a} as a difference quotient, with the quantity
\[
\frac{t_{i+k-j} - t_i}{k-j}
\]
representing a mean mesh length of sorts on the interval $\left[t_i,t_{i+k-j}\right]$. We note that the case where $t$ contains replicated knots leads to division by zero. This is, however, a trivial situation, since for $t_i = t_{i+k-j}$, we have $B_i = 0$, and we take $\frac{0}{0} = 0$.


